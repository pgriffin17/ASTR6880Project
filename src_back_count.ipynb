{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ciao_contrib.runtool as rt\n",
    "import sherpa.astro.ui as ui\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "#astropy is used to read WCS position information from fits files for region_count\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord, Distance\n",
    "\n",
    "\n",
    "def region_count(epoch_in):\n",
    "    '''\n",
    "    write _summary.txt files with the count rate and upper and lower bounds on the 90% confidence interval\n",
    "    '''\n",
    "    srcflx = rt.srcflux\n",
    "    srcflx.punlearn() #Restore the system defaults for a CIAO parameter file.\n",
    "    srcflx.infile = f'data/merge_test/epoch_{epoch_in}/merged_evt.fits'\n",
    "    with fits.open(srcflx.infile) as f:\n",
    "        loc = SkyCoord(f[1].header['RA_NOM']*u.deg,f[1].header['DEC_NOM']*u.deg)\n",
    "        loc_str = loc.ra.to_string(unit=u.hourangle, sep=':', pad=True, precision=2) + \" \" + loc.dec.to_string(unit=u.degree, sep=':', pad=True, precision=2)\n",
    "    srcflx.pos = loc_str #Reads RA, DEC columns as a position in sexagesimal \"degree:arcmin:arcsec\" format\n",
    "    srcflx.outroot = f'data/merge_test/epoch_{epoch_in}/srcflux_products/'\n",
    "    srcflx.srcreg = f'regions/srcwcs.reg' #region used to calculate the source counts\n",
    "    srcflx.bkgreg = f'regions/bkgwcs.reg'#region used to calculate the background counts\n",
    "    srcflx.clobber = 'yes'\n",
    "    srcflx.verbose = 0 #Default =1, 0 suppresses the long print statement\n",
    "    srcflx()\n",
    "    \n",
    "    #a _summary.txt file is produces with the count rate and an unjustified flux\n",
    "    \n",
    "def read_counts(epoch):\n",
    "    outroot = f'data/merge_test/epoch_{epoch}/srcflux_products/'\n",
    "    with open(outroot+'_summary.txt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            count_rate_match = re.search(r'[\\d\\.E\\-]*\\s(c/s)',line)\n",
    "            lb_match = re.search(r'\\([\\d\\.E\\-]*\\,', line)\n",
    "            ub_match = re.search(r'\\,\\[\\d\\.E\\-]*\\)', line)\n",
    "            #0001|13 9 48.47 -23 22 58.4  Rate           0.0014 c/s (0.00104,0.00183)      \n",
    "            if count_rate_match:\n",
    "                cr = float(count_rate_match.group(0)[0:-4])\n",
    "                lb = float(lb_match.group(0)[1:-1])\n",
    "                ub = float(ub_match.group(0)[1:-1])\n",
    "                return(cr, lb, ub)\n",
    "\n",
    "\n",
    "def merge_by_epoch(obsid_in_list):\n",
    "    '''\n",
    "    params\n",
    "    ------\n",
    "    obsid_in_list : list\n",
    "        List of observation IDs to be merged\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    ## previously used flxobs()\n",
    "    mrgobs = rt.merge_obs\n",
    "    epoch=4\n",
    "    for obsid_row in obsid_in_list:\n",
    "        mrgobs.punlearn()\n",
    "        mrgobs.infiles = str()\n",
    "        for obsid in obsid_row:\n",
    "            if mrgobs.infiles is None:\n",
    "                mrgobs.infiles = f'data/{obsid}/repro/acisf{obsid}_repro_evt2.fits'\n",
    "            else:\n",
    "                mrgobs.infiles += f', data/{obsid}/repro/acisf{obsid}_repro_evt2.fits' ## includes leading comma\n",
    "        print('\\nEpoch: '+str(epoch))\n",
    "        print(mrgobs.infiles)\n",
    "\n",
    "        mrgobs.outroot = f'data/merge_test/epoch_{epoch}'\n",
    "        mrgobs.clobber='yes'\n",
    "        #mrgobs()\n",
    "\n",
    "import spreadsheet\n",
    "\n",
    "def lightcurve_counts(epoch_in_list):\n",
    "    '''\n",
    "    produce a light curve of count rate vs time\n",
    "    '''\n",
    "    counts_list = []\n",
    "    t_list = []\n",
    "    yerr_list = []\n",
    "    xerr_list = []\n",
    "    for epoch in epoch_in_list:\n",
    "        [count, lb, ub] = region_count(obsid)\n",
    "        counts_list.append(count)\n",
    "        [t_t0,exp_time]=spreadsheet.obsid_header_parse(obsid)\n",
    "        t_list.append(t_t0)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.errorbar(t_list, counts_list, fmt='bo', yerr=lb+ub, xerr=exp_time)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs ID 20861 observed a count rate of 0.0014 c/s\n"
     ]
    }
   ],
   "source": [
    "#reproject(20936, 20860)\n",
    "obsid = 20861\n",
    "[count, lb, ub] = region_count(obsid)\n",
    "print(f'Obs ID {obsid} observed a count rate of {count} c/s')\n",
    "\n",
    "from spreadsheet import epoch_obsid_list as eol\n",
    "merge_by_epoch(eol)\n",
    "\n",
    "lightcurve_counts(range(len(eol)))\n",
    "\n",
    "#merge_observations([20860, 20936])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ciao-4.15')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa0ed6ea5fdefd83fab7eb4cb6966f67b14a46d682529109a8514cc91561ea32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
